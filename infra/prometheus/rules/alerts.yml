# Alert Rules for Listen Stream
# Evaluated every 15s (prometheus.yml: evaluation_interval)

groups:
  # ─── Service Health ────────────────────────────────────────────────────────
  - name: service_health
    rules:
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "Service {{ $labels.job }} on {{ $labels.instance }} has been down for more than 1 minute."
          runbook: "https://wiki.listen-stream.com/runbooks/service-down"

      - alert: HighErrorRate
        expr: |
          (
            sum(rate(listen_stream_http_requests_total{status=~"5.."}[5m])) by (service)
            /
            sum(rate(listen_stream_http_requests_total[5m])) by (service)
          ) > 0.05
        for: 2m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "High error rate on {{ $labels.service }}"
          description: "Service {{ $labels.service }} has >5% error rate (current: {{ $value | humanizePercentage }}) for 2+ minutes."

      - alert: CriticalErrorRate
        expr: |
          (
            sum(rate(listen_stream_http_requests_total{status=~"5.."}[5m])) by (service)
            /
            sum(rate(listen_stream_http_requests_total[5m])) by (service)
          ) > 0.20
        for: 1m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "Critical error rate on {{ $labels.service }}"
          description: "Service {{ $labels.service }} has >20% error rate (current: {{ $value | humanizePercentage }})."

  # ─── Latency Alerts ────────────────────────────────────────────────────────
  - name: latency
    rules:
      - alert: HighP99Latency
        expr: |
          histogram_quantile(0.99,
            sum(rate(listen_stream_http_request_duration_seconds_bucket[5m])) by (service, le)
          ) > 0.5
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "P99 latency high on {{ $labels.service }}"
          description: "P99 latency for {{ $labels.service }} is {{ $value | humanizeDuration }} (threshold: 500ms)."

      - alert: CriticalP99Latency
        expr: |
          histogram_quantile(0.99,
            sum(rate(listen_stream_http_request_duration_seconds_bucket[5m])) by (service, le)
          ) > 2.0
        for: 2m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "Critical P99 latency on {{ $labels.service }}"
          description: "P99 latency for {{ $labels.service }} is {{ $value | humanizeDuration }} (threshold: 2s)."

  # ─── WebSocket ─────────────────────────────────────────────────────────────
  - name: websocket
    rules:
      - alert: WebSocketConnectionsHigh
        expr: listen_stream_websocket_active_connections > 8000
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "WebSocket connections approaching limit"
          description: "Active WebSocket connections: {{ $value }} (limit: 10000)"

      - alert: WebSocketConnectionsAtLimit
        expr: listen_stream_websocket_active_connections > 9500
        for: 1m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "WebSocket connection limit nearly reached"
          description: "Active WebSocket connections: {{ $value }} (limit: 10000). New connections will be rejected!"

  # ─── Database ──────────────────────────────────────────────────────────────
  - name: database
    rules:
      - alert: PostgreSQLDown
        expr: pg_up == 0
        for: 30s
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL instance {{ $labels.instance }} is not responding."

      - alert: PostgreSQLHighConnections
        expr: |
          pg_stat_activity_count{state="active"} > 80
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "PostgreSQL high connection count"
          description: "PostgreSQL has {{ $value }} active connections (threshold: 80)."

      - alert: PostgreSQLSlowQueries
        expr: |
          rate(pg_stat_activity_max_tx_duration{state="active"}[5m]) > 30
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "PostgreSQL slow queries detected"
          description: "PostgreSQL has slow-running transactions exceeding 30 seconds."

  # ─── Redis ─────────────────────────────────────────────────────────────────
  - name: redis
    rules:
      - alert: RedisDown
        expr: redis_up == 0
        for: 30s
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Redis is down"
          description: "Redis instance {{ $labels.instance }} is not responding."

      - alert: RedisHighMemory
        expr: |
          redis_memory_used_bytes / redis_memory_max_bytes > 0.85
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "Redis memory usage high"
          description: "Redis memory usage is {{ $value | humanizePercentage }} (threshold: 85%)."

      - alert: RedisTooManyConnections
        expr: redis_connected_clients > 1000
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "Redis too many connections"
          description: "Redis has {{ $value }} connected clients."

  # ─── Consul ────────────────────────────────────────────────────────────────
  - name: consul
    rules:
      - alert: ConsulHealthServiceUnhealthy
        expr: |
          consul_health_service_status{status="critical"} > 0
        for: 1m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Consul service critical: {{ $labels.service_name }}"
          description: "Service {{ $labels.service_name }} has critical health check status."

  # ─── Upstream Proxies ──────────────────────────────────────────────────────
  - name: upstream
    rules:
      - alert: AllUpstreamsFailing
        expr: |
          sum(listen_stream_cache_l1_misses_total) > 0
          and
          sum(rate(listen_stream_http_requests_total{status="200",service="proxy-svc"}[5m])) == 0
        for: 2m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "All upstream music sources are failing"
          description: "proxy-svc cannot fetch playback URLs from any upstream (QQ/Joox/NetEase/Kugou)."

  # ─── Host Resources ────────────────────────────────────────────────────────
  - name: host_resources
    rules:
      - alert: HighCPUUsage
        expr: |
          100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 85
        for: 10m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value }}% (threshold: 85%)."

      - alert: LowDiskSpace
        expr: |
          (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) < 0.15
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Only {{ $value | humanizePercentage }} disk space remaining."

      - alert: HighMemoryUsage
        expr: |
          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.90
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value | humanizePercentage }} (threshold: 90%)."
