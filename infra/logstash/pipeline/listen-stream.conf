# Logstash Pipeline for Listen Stream
# Receives service logs via Beats or direct TCP/UDP and ships to Elasticsearch
# Log retention policy: 30 days (enforced via ILM in Elasticsearch)

# ─── INPUT ────────────────────────────────────────────────────────────────────
input {
  # Receive logs from services via Beats (Filebeat)
  beats {
    port => 5044
    type => "beats"
  }

  # Direct TCP input for services that push JSON logs
  tcp {
    port    => 5000
    codec   => json_lines
    type    => "tcp-json"
  }

  # UDP input (lightweight, fire-and-forget)
  udp {
    port  => 5000
    codec => json
    type  => "udp-json"
  }

  # HTTP input — receive logs via POST /
  http {
    port  => 8080
    codec => json
    type  => "http-json"
  }
}

# ─── FILTER ───────────────────────────────────────────────────────────────────
filter {
  # Parse JSON log body (if not already parsed by codec)
  if [message] =~ /^\{/ {
    json {
      source  => "message"
      target  => "log"
      remove_field => ["message"]
    }
  }

  # Normalize timestamp
  date {
    match => ["[log][time]", "[time]", "ISO8601", "yyyy-MM-dd'T'HH:mm:ss.SSSZ"]
    target => "@timestamp"
    remove_field => ["[log][time]", "time"]
  }

  # Normalize log level
  mutate {
    rename => {
      "[log][level]" => "level"
      "[log][message]" => "message"
      "[log][service]" => "service.name"
      "[log][trace_id]" => "trace.id"
      "[log][span_id]" => "span.id"
      "[log][request_id]" => "request.id"
      "[log][user_id]" => "user.id"
      "[log][ip]" => "client.ip"
      "[log][method]" => "http.method"
      "[log][path]" => "url.path"
      "[log][status]" => "http.response.status_code"
      "[log][duration_ms]" => "event.duration"
      "[log][error]" => "error.message"
    }
  }

  # Uppercase log level
  if [level] {
    mutate {
      uppercase => ["level"]
    }
    # Map log.level field
    mutate {
      add_field => { "[log][level]" => "%{level}" }
    }
  }

  # Add environment tag
  mutate {
    add_field => {
      "environment"     => "${ENVIRONMENT:development}"
      "cluster"         => "listen-stream"
    }
  }

  # Tag error logs
  if [level] == "ERROR" or [level] == "FATAL" {
    mutate {
      add_tag => ["error"]
    }
  }

  # Mask sensitive fields (PII protection)
  # Mask phone numbers: keep first 3 digits, mask middle, keep last 2
  if [message] {
    gsub {
      field => "message"
      pattern => "(?<!\d)(\d{3})\d{4,8}(\d{2})(?!\d)"
      replacement => '\1****\2'
    }
  }

  # Mask Authorization headers in logs
  if [http.request.headers.Authorization] {
    mutate {
      replace => { "[http][request][headers][Authorization]" => "[MASKED]" }
    }
  }

  # Parse duration from nanoseconds to milliseconds
  if [event][duration] {
    ruby {
      code => "event.set('[event][duration_ms]', (event.get('[event][duration]').to_f / 1_000_000).round(2))"
    }
  }

  # Geo-IP enrichment from client IP
  if [client][ip] and [client][ip] !~ /^(10\.|172\.(1[6-9]|2[0-9]|3[01])\.|192\.168\.|127\.|::1)/ {
    geoip {
      source => "[client][ip]"
      target => "[client][geo]"
    }
  }

  # Drop health check and metrics noise
  if [url][path] =~ /^\/(health|metrics|ready)$/ {
    drop {}
  }
}

# ─── OUTPUT ───────────────────────────────────────────────────────────────────
output {
  # ── Elasticsearch (primary) ─────────────────────────────────────────────
  elasticsearch {
    hosts    => ["http://elasticsearch:9200"]
    
    # Dynamic index per service with date suffix (e.g. listen-stream-logs-auth-svc-2026.03.01)
    # Retention enforced via ILM policy: 30-day hot, then delete
    index    => "listen-stream-logs-%{[service][name]:unknown}-%{+YYYY.MM.dd}"
    
    # ILM settings
    ilm_enabled        => true
    ilm_rollover_alias => "listen-stream-logs"
    ilm_policy         => "listen-stream-30d-policy"

    # Template
    manage_template => true
    template_name   => "listen-stream-logs"
    template_overwrite => true

    # Retry
    retry_initial_interval     => 2
    retry_max_interval         => 64
    retry_on_conflict          => 5

    # Bulk
    bulk_max_size  => 500
  }

  # ── Error logs → dedicated index ─────────────────────────────────────────
  if "error" in [tags] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "listen-stream-errors-%{+YYYY.MM.dd}"
    }
  }

  # ── Debug: print to stdout (disable in production) ───────────────────────
  if "${LOGSTASH_DEBUG:false}" == "true" {
    stdout {
      codec => rubydebug
    }
  }
}
